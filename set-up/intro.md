Welcome to Scenario 1 of the "Serving a Machine Learning Model in a Private Cloud" Tutorial.

This tutorial has three scenarios.

Scenario 1:
Environment Set-up

Scenario 2:
Creating a simple ML model

Scenario 3:
Serve your ML model in Flask, giving your application an endpoint to call.

In this scenario, we will concentrate on environment setup,
This scenario will take us through the steps we need to set up our 
tensorflow and python environment to create a basic ML model.
If you choose to do containers, go with Option 1.
If you chose to do a setup without containers, skip to Option 2.  
You do not need both options. 

The container approach is recommended for this tutorial.

