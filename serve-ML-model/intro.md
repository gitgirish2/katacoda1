Welcome to Scenario 3 (ML Model Serving) of the "Serving a Machine Learning Model in a Private Cloud" Tutorial.

The goal of this tutorial is to provide a basic example of how to set up an environment, create a model and serve a model in order to integrate it into an application.  This scenario assumes that you have completed the first two scenarios.  

At the end of this scenario, you should be able to call an endpoint to your model from your application, have it take in data and save the data to make the scenario evergreen and return a prediction to the caller. 

![ML Integration Flow](/laura-schornack/scenarios/set-up/assets/ML-Model-App-Integration.png)

