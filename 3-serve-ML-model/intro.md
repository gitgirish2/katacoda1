Welcome to Scenario 3 (ML Model Serving) of the "Serving a Machine Learning Model in a Private Cloud" Tutorial.

The goal of this tutorial is to provide a basic example of how to set up an environment, create a model and serve a model in order to integrate it into an application.  This scenario assumes that you have completed the first two scenarios.

The first scenario walked through the setup.
The second scenario walked us through the first 5 steps of the ML Development Cycle.
![ML Integration Cycle](ml-cycle.png) 

This scenario will walk through the last step of the ML Development Cycle: Interface.

![ML Integration Cycle](interface.png)

At the end of this scenario, you should be able to use the interface that we created for our Machine Learning Model.  You will do this by calling an endpoint to your model from your application and return the output to the caller. 

 


