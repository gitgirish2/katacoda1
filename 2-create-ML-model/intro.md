Welcome to Scenario 2 (Creating a simple ML Model) of the "Serving a Machine Learning Model in a Private Cloud" Tutorial.

In this scenario, we will be creating a simple ML model.

This scenario assumes that you have completed Scenario 1:
Environment Set-up.  When you are done with this scenario, please continue to Scenario 3: Serve your ML model in Flask, giving your application an endpoint to call.

At the end of this three scenario tutorial, you should be able to call an endpoint to your model from your application, have it take in data and save the data to make the scenario evergreen and return a prediction to the caller. 
The goal of this tutorial is to provide a basic example of how to set up an environment, create a model and serve a model in order to integrate it into an application.  

This scenario uses an iterative approach to development.
In the next 10 steps, we will go through each of the steps of this cycle. 

![ML Integration Cycle](ml-cycle-2.png)

 




